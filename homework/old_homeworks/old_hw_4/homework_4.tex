\documentclass[10pt]{article}
 \usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts,color, titling}
 \usepackage{listings}
\usepackage{gensymb}

\setlength{\droptitle}{-20mm} 

\usepackage[colorlinks=true,linkcolor=blue,urlcolor=blue]{hyperref}

\title{Homework \# 4}
\author{PHY-905-003, Computational Astrophysics and
  Astrostatistics\\Spring 2017}
 \date{} % leave blank to have no date

\begin{document}
 
\maketitle

\vspace{-8mm}

\noindent \textbf{This assignment is due on Sunday April 30, 2017.}  
Turn in all materials via GitHub.  Include your code, plots, and
answers to any questions asked in your assignment.  Your code must (1)
be easily readable, with good use of whitespace, clear variable names,
and adequate commenting (which documents design and purpose, not
mechanics) and (2) use functions to break up code into logical
components.  The solutions to individual problems should be saved in
separate, clearly-named source files or Jupyter notebooks.  Plots
should have easily readable and logical axis labels and titles, and
the source code and data used to generate the plots should be
included.  Questions should be answered in the file
\texttt{ANSWERS.md} or in a \LaTeX-created PDF document of a similar
name (e.g., \texttt{ANSWERS.pdf}).


\vspace{5mm}

\noindent {\large\textbf{Part 1:}}   
The
\href{https://simple.wikipedia.org/wiki/Travelling\_salesman\_problem}{Traveling
Salesman Problem} is a classic problem in computer science where the
focus is on optimization.  The problem is as follows: Imagine there is
a salesman who has to travel to $N_C$ cities.  The order is
unimportant, as long as he only visits each city once on each trip,
and finishes where he started.  The salesman wants to keep the
distance traveled (and thus travel costs) as low as possible.  This
problem is interesting for a variety of reasons - it applies to
transportation (finding the most efficient bus routes), logistics
(finding the best UPS or FedEx delivery routes for some number of
packages), or in optimizing manufacturing processes to reduce cost.
In astrophysics, it is akin to model parameter optimization.  The
Traveling Salesman Problem is extremely difficult to solve exactly for large
numbers of cities - testing every possible combination of cities would
take N$_C$! individual tests.  As a result, methods to quickly find a
``good enough'' solution are of great interest.

In this problem, you are going to use the code in
\texttt{traveling\_salesman.py} to minimize the traveling salesman
problem for $N_C = 30$ cities to find a ``good enough'' solution.  
Your code should take some number of
iterations, doing the following at each step:

\begin{enumerate}
\item Randomly swap $N_S$ contiguous cities in the array of cities - in other words, if you have cities
  (1,2,3,4,5, 6,7,8,9,10) for $N_S=2$ you could swap two pairs of cities
  to get (1,2,8,9,5, 6,7,3,4,10).  $N_S$ is typically 1, but can be more than 1
  if you wish.
\item Check the total distance traversed by the salesman.
\item If the new ordering results in a shorter path, keep it.  If not, throw it away.
\end{enumerate}

You stop when you attain convergence.  Decide what that means in this
context and make sure to report it!  Also keep track of the steps and
the minimum distance traveled as a function of number of iteration and
plot out the minimum distance as a function of step. (If you're
feeling ambitious, make a movie of what it looks like as your
simulation evolves toward the minimum path.)

Some questions to answer/tests to do:

\begin{enumerate}
\item How do you decide when to stop?  
\item Does varying $N_S$ from 1-5, but keeping it constant per run,
  significantly affect the rate of convergence?
\item Does allowing $N_S$ to randomly vary from 1-5 every time step in
  a single run significantly speed convergence? 
\item Assuming you can test one model per microsecond 
  per core on the Blue Waters supercomputer (which has approximately
  $3 \times 10^5$ computational cores), how long would it take to test
  every single combination for $N_C = 30$, and how does that compare
  to how long it takes to get a reasonably good solution using your implementation?
\end{enumerate}

Note that you should do at least 10 trials per run to get typical behavior!

\newpage
%\vspace{5mm}
\noindent {\large\textbf{Part 2:}}  It has been hypothesized that the
stellar initial mass function may have an environmental dependence.
To test this, you are being provided with two data files containing a
list of measured stellar masses for two separate star clusters -- one
toward the galactic anticenter (\texttt{IMF\_1.dat}) and the other
very close to the center of the galaxy (\texttt{IMF\_2.dat}).  Given
the distances involved, only the masses of stars with masses greater
than 2~M$_\odot$ could be measured.  Using the statistical techniques
that you've learned this semester, (1) argue whether or not the
stellar mass distributions of the two star clusters appear to have the
same mass function, and (2) quantify your confidence in this result.
Clearly explain the statistical techniques that you have used for both
of these things!  \textbf{Complicating factors:} Note that the star
clusters have substantially different total masses and somewhat
different (non-zero) ages.  How might this affect your approach?

\vspace{5mm}
\noindent {\large\textbf{Part 3:}}   We're going to examine exoplanet
data obtained using two different methods -- by the transit method
(using, e.g., the \href{https://kepler.nasa.gov/}{Kepler mission}), and by using radial velocity
measurements of the central star.  For the transit method we will use
the star \href{http://keplerebs.villanova.edu/overview/?k=8554498}{KIC-8554498} (in the data file
\texttt{KIC-8554498\_lightcurve.dat}, which contains the relative flux
of the star as a function of time since the start of the Kepler
mission) and for radial velocity measurements we will use \href{http://exoplanet.eu/catalog/51_peg_b/}{51-Pegasi}
(in the data file \texttt{51\_Pegasi\_RadVel.dat}, which contains the
Julian date, the star's radial velocity, and the error in the radial
velocity).

For each of the two files, do the following:

\begin{enumerate}

\item Plot the light curve or radial velocity data for each of the two
planetary systems, zooming in as necessary to show interesting
features.  Can you see by eye the evidence of exoplanets in the data?
If so, what do you see?

\item Use the SciPy or Astropy Lomb-Scargle periodogram routines to identify
the orbital periods of the exoplanets orbiting these stars.  Include
your plots, zooming in on regions as necessary.  Note any interesting
features in the periodogram.  Are the results consistent with the
expected periods of the planets orbiting 51 Peg ($P \simeq 4.23$~days)
and KIC-8554498 ($P \simeq 4.78$~days)?  What features do you see in
these graphs, and what do you hypothesize causes them?

\end{enumerate}


\vspace{5mm}

\noindent {\large\textbf{Part 4:}} We're going to continue using the
data for
\href{https://en.wikipedia.org/wiki/51\_Pegasi\_b}{51-Pegasi}, which
was the \href{http://adsabs.harvard.edu/abs/1995Natur.378..355M}{first
  confirmed discovery} of a planet outside of our own solar system.
Assuming a period of $P = 4.230785$~days, created a stacked radial
velocity curve that folds all of the orbital data you have been
provided into a single period.  Then, create a model for the observed
radial velocity curve of a single planet in a circular orbit around a
star (you may wish to
\href{https://en.wikipedia.org/wiki/Doppler\_spectroscopy}{start
  here}), and use a Bayesian Markov Chain Monte Carlo algorithm to
determine the planet's mass (really $M \sin(i)$), the semi-major axis
of the orbit, and the orbital period.  Take the mass of 51 Pegasi as a
given (M$_* = 1.06$~M$_\odot$), and assume reasonably broad priors for
the other quantities.  Use a reduced sum of squares to estimate the
agreement between the model and the data.  Using the data and the
errors provided, can you reproduce the values for the period,
semi-major axis of the orbit, and mass of the planet?  Show 2D
histograms for various combinations of the unknowns, and identify any
degeneracies between model parameters that may exist.

\end{document}

