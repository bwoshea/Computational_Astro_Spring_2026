{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in i and z band magnitudes and errors\n",
    "redshift, K0, Temperature, Lbol = np.loadtxt(\"accept_main.txt\",skiprows=2,\n",
    "                                             usecols=[3,4,7,8],unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Temperature,Lbol,'bo')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Temperature [keV]')\n",
    "plt.ylabel(r'Luminosity [$10^{44}$ ergs/s]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Temperature,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Lbol,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "logTemp = np.log10(Temperature[Lbol > 0.0])\n",
    "logLbol = np.log10(Lbol[Lbol > 0.0])\n",
    "\n",
    "vals_returned = linregress(logTemp, logLbol)\n",
    "\n",
    "print(vals_returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Temp_for_fit = np.linspace(0.5,20.0,50)\n",
    "Lum_from_fit = (10**vals_returned[1]) * (Temp_for_fit**vals_returned[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(10**logTemp,10**logLbol,'bo')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Temperature [keV]')\n",
    "plt.ylabel(r'Luminosity [$10^{44}$ ergs/s]')\n",
    "plt.plot(Temp_for_fit,Lum_from_fit,'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(logTemp,logLbol,'bo')\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('Temperature [keV]')\n",
    "plt.ylabel(r'Luminosity [$10^{44}$ ergs/s]')\n",
    "plt.plot(np.log10(Temp_for_fit),np.log10(Lum_from_fit),'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(redshift,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONVENIENCE FUNCTIONS: these are needed for our fitting\n",
    "\n",
    "def est_error(ydata,yguess,error):\n",
    "    '''\n",
    "    Takes in the observed data, our current step's estimated y-values \n",
    "    for the model, and our guess for the errors in the data.\n",
    "    \n",
    "    Returns sum-of-squares error assuming a 2-parameter model\n",
    "    '''\n",
    "    return ((ydata-yguess)**2/(2*error**2)).sum()/(ydata.size-2)\n",
    "\n",
    "\n",
    "def est_model_vals(alpha,b,logT):\n",
    "    '''\n",
    "    Given x-values and our MCMC code's estimates for A and B, this returns \n",
    "    estimated y values that we can compare to the actul data .\n",
    "    '''\n",
    "    return b + alpha*logT\n",
    "\n",
    "def prior(alpha, b):\n",
    "    alpha0 = 6.0\n",
    "    sigma_alpha = 3\n",
    "    b0 = -3.0\n",
    "    sigma_b = 3.0\n",
    "    \n",
    "    p_alpha = (2.0*np.pi*sigma_alpha**2)**-0.5 * np.exp( -(alpha-alpha0)**2/(2.0*sigma_alpha**2))\n",
    "\n",
    "    #if alpha < 2.7:\n",
    "    #    p_alpha = 0.0\n",
    "    \n",
    "    p_b = (2.0*np.pi*sigma_b**2)**-0.5 * np.exp( -(b-b0)**2/(2.0*sigma_b**2))\n",
    "    return p_alpha*p_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The actual MCMC code.\n",
    "import numpy.random as npr\n",
    "\n",
    "estimated_error = 0.2\n",
    "\n",
    "# Initial guesses for A and B\n",
    "# Outcome should be relatively insensitive to these guesses!\n",
    "alpha_old = 3\n",
    "b_old = -1\n",
    "\n",
    "# Range of step sizes that we take (linearly in -dA...dA and -dB...dB).\n",
    "# This has to be relatively small, but if you make it too small you don't get\n",
    "# Good sampling of the probability distribution function.\n",
    "dA=dB=0.01\n",
    "\n",
    "# Total number of points we're going to sample (should be at least 10^4)\n",
    "Npts = 100000\n",
    "N_burn = 1000\n",
    "\n",
    "# Initial model values and 'error' for our starting position\n",
    "y_old = est_model_vals(alpha_old,b_old,logTemp)\n",
    "err_old = est_error(logLbol,y_old,estimated_error)\n",
    "\n",
    "#print(\"y_old:\",y_old)\n",
    "#print(\"err_old:\",err_old)\n",
    "\n",
    "# These lists keep track of our Markov Chain and errors so we can get our PDF later.\n",
    "alpha_guess = []\n",
    "b_guess = []\n",
    "errors = []\n",
    "\n",
    "iter_count = 0\n",
    "\n",
    "plt.plot(10**logTemp,10**logLbol,'bo')\n",
    "plt.plot(10**logTemp,10**y_old,'r-',linewidth=4)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "'''\n",
    "This loop is where the magic happens.  We generate a new guess at (A,B) and compare\n",
    "it to our original values using the chi^2 value.  If the new guess is better, we automatically\n",
    "step in that direction.  If the new guess is worse, we still sometimes step in that direction if\n",
    "a random number in the range [0,1) is pess than the ratio of the chi^2 values for the old and new \n",
    "choices of (A,B). \n",
    "'''\n",
    "for i in range(Npts):\n",
    "    \n",
    "    # Guess for our new point (A,B)\n",
    "    alpha_new = alpha_old + npr.normal(0.0,dA)\n",
    "    b_new = b_old + npr.normal(0.0,dB)\n",
    "\n",
    "    # model values based on the new A and B values\n",
    "    ynew = est_model_vals(alpha_new,b_new,logTemp)\n",
    "    \n",
    "    # sum of squares value comparing data and model given our estimate\n",
    "    # of the errors in the data.\n",
    "    err_new = est_error(logLbol, ynew, estimated_error)\n",
    "    \n",
    "    \n",
    "    # acceptance probability - ratio of likelihoods for old and new data points.\n",
    "    p_accept = np.exp(-err_new+err_old) *prior(alpha_new,b_new)/prior(alpha_old,b_old)\n",
    "\n",
    "    #print('a,b,e,p:', alpha_new, b_new, err_new, p_accept)\n",
    "    \n",
    "    \n",
    "    # if R < p_accept, we keep this point.  Otherwise, keep on moving!\n",
    "    if npr.random() < p_accept:\n",
    "\n",
    "        #print('a,b,enew,eold,p:', alpha_new, b_new, err_new, err_old, err_new-err_old,p_accept)\n",
    "\n",
    "        alpha_old = alpha_new\n",
    "        b_old = b_new\n",
    "        err_old = err_new\n",
    "        \n",
    "        #plt.plot(10**logTemp,10**ynew,alpha=0.3)#,'r--')\n",
    "        \n",
    "        if iter_count > N_burn:\n",
    "            alpha_guess.append(alpha_old)\n",
    "            b_guess.append(b_old)\n",
    "            errors.append(err_old)\n",
    "\n",
    "    iter_count += 1\n",
    "\n",
    "print(\"kept:\",len(alpha_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alpha_guess,b_guess,'b-')#,A_user,B_user,'co',markersize=10)\n",
    "#plt.plot(Aguess[-1],Bguess[-1],'gs',markersize=10)\n",
    "plt.xlabel('alpha vals')\n",
    "plt.ylabel('b vals')\n",
    "plt.title('Markov Chain for estimate of (A,B)')\n",
    "len(b_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "cts,xbin,ybin,img = plt.hist2d(alpha_guess, b_guess, bins=60,norm=LogNorm())\n",
    "#plt.plot(A_user,B_user,'co',markersize=10)\n",
    "\n",
    "# use np.argwhere() to find the bin(s) with the max counts\n",
    "vals=np.argwhere(cts==cts.max())\n",
    "\n",
    "# use those to guess our best values of A, B.  If there are more than one bins with the max\n",
    "# number of counts, we're just using the first one we come to.  (This is not the best idea, but\n",
    "# it makes the point)\n",
    "Abest = xbin[vals[0,0]]\n",
    "Bbest = ybin[vals[0,1]]\n",
    "plt.plot(Abest,Bbest,'wD',markersize=10)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.xlabel('A vals')\n",
    "plt.ylabel('B vals')\n",
    "plt.title('2D Histogram of walker positions')\n",
    "\n",
    "print(\"A, B best:\",Abest,Bbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lum_from_bayes_fit = 10**Bbest * Temp_for_fit**Abest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(10**logTemp,10**logLbol,'bo')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Temperature [keV]')\n",
    "plt.ylabel(r'Luminosity [$10^{44}$ ergs/s]')\n",
    "plt.plot(Temp_for_fit,Lum_from_fit,'r-',linewidth=4)\n",
    "plt.plot(Temp_for_fit,Lum_from_bayes_fit,'g-',linewidth=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A2_T500, A2_Terr, A2_Lbol, A2_Lerr = np.loadtxt(\"ACCEPT2_sanitized.dat\",skiprows=5,\n",
    "                                             usecols=[0,1,2,3],unpack=True)\n",
    "\n",
    "plt.plot(A2_T500,A2_Lbol,'bo')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Temperature [keV]')\n",
    "plt.ylabel(r'Luminosity [ergs/s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
