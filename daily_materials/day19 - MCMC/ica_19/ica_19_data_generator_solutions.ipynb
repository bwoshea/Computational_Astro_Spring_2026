{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(5998821)\n",
    "\n",
    "bins = 1000\n",
    "fraction = 0.04\n",
    "t = np.linspace(0,100,bins)\n",
    "sigma = 4.0  # high noise is sigma=4, low-noise is sigma=0.5\n",
    "datafilename = \"timeseries.txt\"   # add _lownoise for the low-noise version!\n",
    "\n",
    "A = 8.3\n",
    "omega = 2.0*np.pi/35.0 \n",
    "phi = 0.2*np.pi\n",
    "\n",
    "f = A * np.sin(omega*t + phi)\n",
    "\n",
    "bool_array = npr.rand(bins) < fraction\n",
    "\n",
    "f_error = npr.normal(0,sigma,t[bool_array].size)\n",
    "\n",
    "f_data = f[bool_array] + f_error\n",
    "\n",
    "t_data = t[bool_array]\n",
    "#print(bool_array)\n",
    "#plt.plot(t[bool_array],f[bool_array],'b-')\n",
    "plt.errorbar(t_data,f_data,yerr=f_error,fmt='bo')\n",
    "\n",
    "print(\"A:\",A)\n",
    "print(\"Omega:\", omega)\n",
    "print(\"phi:\", phi)\n",
    "\n",
    "np.savetxt(datafilename,np.c_[t_data,f_data,np.abs(f_error)],fmt=\"%.6e\",\n",
    "           header=\"# time [s], flux(t) [arb. units], flux_error [arb. units]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_error(ydata,yguess,error):\n",
    "    '''\n",
    "    Takes in the observed data, our current step's estimated y-values \n",
    "    for the model, and our guess for the errors in the data.\n",
    "    \n",
    "    Returns sum-of-squares error assuming a 2-parameter model\n",
    "    '''\n",
    "    return ((ydata-yguess)**2/(2*error**2)).sum()/(ydata.size-3)\n",
    "\n",
    "\n",
    "def est_model_vals(A,omega,phi,t):\n",
    "    '''\n",
    "    Given x-values and our MCMC code's estimates for A and B, this returns \n",
    "    estimated y values that we can compare to the actul data .\n",
    "    '''\n",
    "    return A * np.sin(omega*t + phi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The actual MCMC code.\n",
    "\n",
    "# Initial guesses for A and B\n",
    "# Outcome should be relatively insensitive to these guesses!\n",
    "A_old = 6.0\n",
    "Omega_old = 0.2\n",
    "phi_old = 0.3\n",
    "\n",
    "# Range of step sizes that we take (linearly in -dA...dA and -dB...dB).\n",
    "# This has to be relatively small, but if you make it too small you don't get\n",
    "# Good sampling of the probability distribution function.\n",
    "dA=0.2\n",
    "dOmega=0.01\n",
    "dphi=0.01\n",
    "\n",
    "# Total number of points we're going to sample (should be at least 10^4)\n",
    "Npts = 1000000\n",
    "N_burn = 1000\n",
    "\n",
    "# Initial model values and 'error' for our starting position\n",
    "y_old = est_model_vals(A_old,Omega_old,phi_old,t_data)\n",
    "\n",
    "err_old = est_error(f_data,y_old,f_error)\n",
    "\n",
    "# These lists keep track of our Markov Chain and errors so we can get our PDF later.\n",
    "A_guess = []\n",
    "Omega_guess = []\n",
    "Phi_guess = []\n",
    "errors = []\n",
    "\n",
    "iter_count = 0\n",
    "\n",
    "for i in range(Npts):\n",
    "    \n",
    "    # Guess for our new point (A,B)\n",
    "    A_new = A_old + npr.uniform(-dA,dA)\n",
    "    Omega_new = Omega_old + npr.uniform(-dOmega,dOmega)\n",
    "    phi_new = phi_old + npr.uniform(-dphi,dphi)\n",
    "    \n",
    "    # model values based on the new A and B values\n",
    "    ynew = est_model_vals(A_new,Omega_new,phi_new,t_data)\n",
    "    \n",
    "    # sum of squares value comparing data and model given our estimate\n",
    "    # of the errors in the data.\n",
    "    err_new = est_error(f_data, ynew, f_error)\n",
    "    \n",
    "    # acceptance probability - ratio of likelihoods for old and new data points.\n",
    "    p_accept = np.exp(-err_new+err_old)\n",
    "    \n",
    "    # if R < p_accept, we keep this point.  Otherwise, keep on moving!\n",
    "    if npr.random() < p_accept:\n",
    "        A_old = A_new\n",
    "        Omega_old = Omega_new\n",
    "        phi_old = phi_new\n",
    "        \n",
    "        err_old = err_new\n",
    "        \n",
    "        if iter_count > N_burn:\n",
    "            A_guess.append(A_old)\n",
    "            Omega_guess.append(Omega_old)\n",
    "            Phi_guess.append(phi_old)\n",
    "            errors.append(err_old)\n",
    "\n",
    "    iter_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Phi_guess,Omega_guess,'b.',phi,omega,'co',markersize=10)\n",
    "#plt.plot(A_guess[-1],Omega_guess[-1],'gs',markersize=10)\n",
    "#plt.xlabel('A vals')\n",
    "#plt.ylabel('B vals')\n",
    "#plt.title('Markov Chain for estimate of (A,B)')\n",
    "print(len(A_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "cts,xbin,ybin,img = plt.hist2d(Phi_guess, Omega_guess, bins=60,norm=LogNorm())\n",
    "plt.plot(phi,omega,'co',markersize=10)\n",
    "plt.xlabel('phi')\n",
    "plt.ylabel('omega')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A_guess,Omega_guess,'b.',A,omega,'co',markersize=10)\n",
    "#plt.plot(A_guess[-1],Omega_guess[-1],'gs',markersize=10)\n",
    "#plt.xlabel('A vals')\n",
    "#plt.ylabel('B vals')\n",
    "#plt.title('Markov Chain for estimate of (A,B)')\n",
    "print(len(A_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts,xbin,ybin,img = plt.hist2d(A_guess, Omega_guess, bins=60,norm=LogNorm())\n",
    "plt.plot(A,omega,'co',markersize=10)\n",
    "plt.xlabel('A')\n",
    "plt.ylabel('omega')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(t,f,'r-')\n",
    "plt.errorbar(t_data,f_data,yerr=f_error,fmt='bo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = plt.hist(A_guess,bins=100,density=True)\n",
    "plt.xlabel(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = plt.hist(Phi_guess,bins=100,density=True)\n",
    "plt.xlabel(\"Phi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = plt.hist(Omega_guess,bins=100,density=True)\n",
    "plt.xlabel(\"Omega\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
