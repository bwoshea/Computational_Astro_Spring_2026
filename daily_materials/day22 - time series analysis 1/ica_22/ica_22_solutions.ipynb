{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series analysis in unevenly-spaced datasets\n",
    "\n",
    "In this assignment, we're going to be working with a the same time series dataset of a Galactic [low-mass x-ray binary](https://en.wikipedia.org/wiki/X-ray_binary#Low-mass_X-ray_binary), GX 5-1 ([Jonker et al. 2002](http://adsabs.harvard.edu/abs/2002MNRAS.333..665J)), as we did in the pre-class assignment.  The difference is that in class today we'll be working with the [Lomb-Scargle Periodogram](https://en.wikipedia.org/wiki/Least-squares_spectral_analysis#The_Lomb.E2.80.93Scargle_periodogram), which can be used to extract information from irregularly-spaced time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get the data!\n",
    "counts = np.loadtxt(\"GX.dat\")\n",
    "print(\"original array shape:\", counts.shape)\n",
    "\n",
    "# the array is the wrong shape because the data is structured oddly.  The counts\n",
    "# are in order in time, and meant to be read left to right, top to bottom.  (So\n",
    "# each row is contiguous in time, and the following row comes after it in time.)\n",
    "# we can sort this out by reshaping the array to be 1D\n",
    "counts_regular = np.reshape(counts,counts.size,order='C')\n",
    "print(\"NEW array shape:     \", counts_regular.shape)\n",
    "\n",
    "# make an array \n",
    "times_regular = np.arange(0.0,counts_regular.size/128.0,1.0/128.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything with Lomb-Scargle, let's first take a quick look at a FFT of the regularly-spaced data to see what to expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.fftpack\n",
    "\n",
    "# do a FFT assuming everything is real\n",
    "yfr = scipy.fftpack.rfft(counts_regular)\n",
    "\n",
    "# frequency bins (remember, rfft returns an array of the same length you put in,\n",
    "# but alternates real/imaginary components so we only want a frequency array that's half\n",
    "# of the size of the counts array)\n",
    "dt = 1./128.\n",
    "xf = np.linspace(0.0, 1.0/(2.0*dt), counts_regular.size//2)\n",
    "\n",
    "# only plotting the real part part of the array returned by rfft\n",
    "plt.plot(xf,2.0/counts_regular.size * np.abs(yfr[1::2]),'b-')\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('power [arbitrary]')\n",
    "plt.title('FFT of count rates')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make the dataset irregularly spaced in time!  We're going to randomly subsample the data, and then we're also going to mask out windows of data (because, e.g., we can't observe many things during the daytime with an optical telescope).  The total amount of data that we're going to keep is 0.5 * frac, since half of the data will be thrown away by the windowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.5  # fraction of data to keep (before windowing)\n",
    "window = 256  # size of windows to mask out \n",
    "\n",
    "npr.seed(8675309)\n",
    "\n",
    "# create a boolean array where only frac of the data is 'True'.\n",
    "bool_array = npr.rand(counts_regular.size) < frac\n",
    "\n",
    "# we are going to make half of the boolean array false by reshaping it into a 2D array, zeroing\n",
    "# out every other row in the zero array, and then reshaping it back to a 1D array.  This is sort\n",
    "# of complicated, but the most compact way of doing this (otherwise we'd have to do a loop)\n",
    "bool_array = bool_array.reshape((bool_array.size//window,window))\n",
    "bool_array[::2,:]=False\n",
    "bool_array = bool_array.reshape((bool_array.size))\n",
    "\n",
    "# now we generate a set of irregularly-spaced counts.\n",
    "counts_irr = counts_regular[bool_array]\n",
    "times_irr  = times_regular[bool_array]\n",
    "\n",
    "# plot it out!\n",
    "# subsampled data is in blue, the original dataset is in red.\n",
    "plt.plot(times_regular,counts_regular,'r.',times_irr,counts_irr,'bo')\n",
    "plt.xlim(0,20)\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('counts/bin')\n",
    "plt.title('Subsampled data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lomb-Scargle\n",
    "\n",
    "Now, implement your own version of the Lomb-Scargle Periodogram (Feigelson equations 11.36 and 11.37), and plot the results for a range of frequencies corresponding to the range of frequencies shown above (say for frequencies between 1 and 60 Hz in steps of $\\Delta f = 1$ Hz).\n",
    "\n",
    "Question: Does your result change as you change the subsampling (the variable ```frac```) and the size of the window where data is removed (the variable ```window```)?  If so, how does the result change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts_irr = counts_regular\n",
    "#times_irr = times_regular\n",
    "\n",
    "'''\n",
    "What I'm trying to do here is get the frequency sampling to be as close to the astropy sampling as possible!\n",
    "'''\n",
    "\n",
    "# total duration of the data sampling\n",
    "baseline = times_irr[-1]-times_irr[0]\n",
    "\n",
    "# number of samples\n",
    "samples = times_irr.size\n",
    "\n",
    "# this is 5 in astropy\n",
    "samples_per_peak = 2\n",
    "\n",
    "# frequency spacing\n",
    "df = 1.0/baseline/samples_per_peak\n",
    "\n",
    "min_freq = 0.5*df\n",
    "\n",
    "# 0.5*samples/baseline = average nyquist frequency = 1 / (2 * avg. delta_t)\n",
    "# but, we know that data is unevenly sampled, so we may be able to get better frequency\n",
    "# data than that.\n",
    "nyquist_factor = 2\n",
    "max_freq = nyquist_factor*(0.5*samples/baseline)\n",
    "\n",
    "# calculate number of frequency bins\n",
    "Nf = 1 + int(np.round((max_freq-min_freq)/df))\n",
    "\n",
    "print(\"number of frequencies from scipy method:\", Nf)\n",
    "\n",
    "frequencies_mine = min_freq + df*np.arange(Nf)\n",
    "\n",
    "# ERASE THIS\n",
    "frequencies_mine = np.arange(1.0,61.0,0.1)\n",
    "\n",
    "power_mine = np.zeros_like(frequencies_mine)\n",
    "\n",
    "print(\"how many frequency bins am I actually using?\", frequencies_mine.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DOING THIS MAKES ALL THE DIFFERENCE\n",
    "\n",
    "This normalizes the y-value so that it has a mean of zero.  Apparently \n",
    "having a dc offset in the values of y (X_i in Feigelson) can cause some\n",
    "fairly unpredictable behavior, and thus it is important to subtract off \n",
    "the mean.  It is CRITICAL to do this.  Feigelson does not mention it; I had\n",
    "to figure it out by reading the astropy source code.  (Dammit.)\n",
    "\n",
    "'''\n",
    "counts_irr -= counts_irr.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times_irr, counts_irr\n",
    "for i in range(frequencies_mine.size):\n",
    "    freq = frequencies_mine[i]\n",
    "    omega = 2.0*np.pi*freq\n",
    "    \n",
    "    # calculate Tau\n",
    "    numer = (np.sin(2.0*omega*times_irr)).sum()\n",
    "    denom = (np.cos(2.0*omega*times_irr)).sum()\n",
    "    tau = np.arctan2(numer,denom)/(2.0*omega)\n",
    "    \n",
    "    variance = np.var(counts_irr)\n",
    "    \n",
    "    power_mine[i] = (0.5/(variance))*( (((counts_irr*np.cos(omega*(times_irr-tau))).sum())**2 \n",
    "                                 / (( (np.cos(omega*(times_irr-tau)))**2).sum())) +   \n",
    "                                (((counts_irr*np.sin(omega*(times_irr-tau))).sum())**2 \n",
    "                                 / (( (np.sin(omega*(times_irr-tau)))**2).sum())) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frequencies_mine,power_mine)\n",
    "#plt.xlim(0,50)\n",
    "#plt.ylim(0.0,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now check your results!  \n",
    "\n",
    "[Astropy](http://www.astropy.org/) is a python package that contains a wide variety of useful astronomy-related Python tools.  It happens to include an [implementation of the Lomb-Scargle periodogram](http://docs.astropy.org/en/stable/stats/lombscargle.html) that is probably more efficient than the one we are writing in class, and it's also a good sanity check on your results.  You may need to update astropy, as the version that came with the Anaconda distribution we installed at the beginning of the semester is a bit old.  To check what version you have, do the following:\n",
    "\n",
    "```\n",
    "import astropy\n",
    "print(astropy.version.version)\n",
    "```\n",
    "\n",
    "If you do not have at least version 1.3 of astropy, you need to upgrade astropy.  At the command line, type:\n",
    "\n",
    "```\n",
    "pip install astropy --upgrade\n",
    "```\n",
    "\n",
    "You may have to quit and restart your Jupyter notebook server to ensure that you have accesss to the new version.\n",
    "\n",
    "**Once you have upgraded,** use the astropy Lomb-Scargle module to check the outputs from your own routine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import LombScargle\n",
    "\n",
    "freq = np.arange(0.8, 1.3, 0.1)\n",
    "frequency, power = LombScargle(times_irr, counts_irr).autopower()\n",
    "plt.plot(frequency,power/power.max(),'r-',alpha=0.5)\n",
    "plt.plot(frequencies_mine,power_mine/power_mine.max(),'b-',alpha=0.5)\n",
    "plt.xlim(20,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
