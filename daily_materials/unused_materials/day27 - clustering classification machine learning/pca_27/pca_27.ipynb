{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering, classification, data mining\n",
    "\n",
    "We'll be using [scikit-learn](http://scikit-learn.org)  ([documentation](http://scikit-learn.org/stable/documentation.html)) and [AstroML](http://www.astroml.org/)  ([documentation](http://www.astroml.org/user_guide/index.html)) for this pre-class assignment.\n",
    "\n",
    "You have been provided two datasets - one real and one fake.  The real dataset is a color-magnitude diagram from the [COMBO-17](https://arxiv.org/abs/astro-ph/0208345) survey ([survey website](https://www.mpia.de/COMBO/combo_index.html)), and the fake dataset is a set of Gaussian blobs of known grouping.  We are going to use clustering algorithms to try to find patterns in this data!\n",
    "\n",
    "The COMBO-17 data should show a \"red sequence\" and a \"blue sequence\" of galaxies, which are roughly visible to the eye in the data.  Can you get the scikit-learn [k-means clustering](http://scikit-learn.org/stable/modules/clustering.html) to find the correct clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake data first!\n",
    "\n",
    "The function below generates a user-specified number of clusters with a user-specified size of each cluster, and then uses k-means clustering to find them.  Try varying the cluster properties and the number of expected clusters and see what happens.  How good of a job does k-means clustering do in finding the correct clusters, particularly when they are near each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_clusters(n_clusters=4,npart=30,fwhm=0.05):\n",
    "    '''\n",
    "    generates fake clusters that have been built out of gaussian blob samples.\n",
    "    \n",
    "    inputs: number of clusters, number of particles per clusters, and FWHM of each \n",
    "    cluster distribution (note: domain is assumed to be a 2D square and 0-1 in each \n",
    "    dimension)\n",
    "    \n",
    "    returns: x position, y position, group number\n",
    "    '''\n",
    "    x = []\n",
    "    y = []\n",
    "    group = []\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        \n",
    "        # group center\n",
    "        xcenter = np.random.rand()\n",
    "        ycenter = np.random.rand()\n",
    "\n",
    "        # add particles to groups with normal distribution \n",
    "        # around group center\n",
    "        for j in range(npart):\n",
    "            x.append(xcenter+np.random.normal(0.0,fwhm))\n",
    "            y.append(ycenter+np.random.normal(0.0,fwhm))\n",
    "            group.append(i)\n",
    "    \n",
    "    return x,y,group\n",
    "\n",
    "# set the random seed to get reproducible results - try setting this to different values!\n",
    "np.random.seed(5998821)\n",
    "\n",
    "# generate some clusters - CHANGE PARAMETERS HERE!\n",
    "n_clusters = 4\n",
    "fwhm = 0.05\n",
    "x,y,g=fake_clusters(n_clusters=n_clusters,fwhm=fwhm)\n",
    "\n",
    "# plot it out!\n",
    "plt.scatter(x,y,c=g,cmap='viridis')\n",
    "plt.xlim(-4*fwhm,1+4*fwhm)\n",
    "plt.ylim(-4*fwhm,1+4*fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.cluster as skcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to stack the data together in a 2xN dimensional numpy \n",
    "# array in order to feed it into the KMeans clustering tool\n",
    "combined_data = np.column_stack((x,y))\n",
    "\n",
    "# here's where the magic happens - note that we have to specify the number of clusters.\n",
    "# KMeans has a bunch of parameters - see what they are!\n",
    "clusters=skcluster.KMeans(n_clusters=4).fit_predict(combined_data)\n",
    "\n",
    "plt.scatter(x,y,c=clusters,cmap='viridis')\n",
    "plt.xlim(-4*fwhm,1+4*fwhm)\n",
    "plt.ylim(-4*fwhm,1+4*fwhm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, vary the random seed, the number of clusters, and the FWHM of the blobs that you generate.  How does K-means clustering do in the varied scenarios?  Furthermore, Scikit-learn's K-means clustering asks you to guess how many clusters there are - what happens when you give it a number that is too large or too small?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now...\n",
    "\n",
    "Read through the [scikit-learn page on clustering](http://scikit-learn.org/stable/modules/clustering.html), as well as their [demonstration of the effects of k-means assumptions](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html#sphx-glr-auto-examples-cluster-plot-kmeans-assumptions-py).  Experiment with a few of the different clustering algorithms described in the first link, and record your observations about the relative properties.  **Repeat the same experiment as above regarding the FWHM of the blobs,** and record your observations below.\n",
    "\n",
    "If you have time, try varying the shapes of the clusters and their distributions in the function above (i.e., non-circular, non-Gaussian) to see how the various algorithsm behave.  Record your observations below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**notes here!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBO-17\n",
    "\n",
    "Now, try the K-means clustering on this observational dataset, which is described above.  Do you get similar results?  Can you reproduce the galaxy red and blue sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V1, V2 = np.loadtxt(\"COMBO17_lowz.dat\",skiprows=1,unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot color-magnitude diagram.  Higher in the y direction means galaxy is \n",
    "# bluer; lower in the y-direction means redder.  Due to the insanity of the\n",
    "# magnitude system, more negative numbers on the x-axis are actually brighter.\n",
    "\n",
    "plt.plot(V1,V2,'b.')\n",
    "plt.xlabel(r'M$_B$ (mag)')\n",
    "plt.ylabel(r'M$_{280}$-M$_B$ (mag)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your data here!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
